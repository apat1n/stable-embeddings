{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13a58a05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users: 6034\n",
      "items: 3125\n",
      "interactions: 574376\n",
      "density: 3.05%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        white-space: pre;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        padding-top: 0;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        padding-bottom: 0;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        line-height: 95%;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "<small>shape: (574376, 3)</small>\n",
       "<thead>\n",
       "<tr>\n",
       "<th>\n",
       "user_id\n",
       "</th>\n",
       "<th>\n",
       "item_id\n",
       "</th>\n",
       "<th>\n",
       "event_ts\n",
       "</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "i64\n",
       "</td>\n",
       "<td>\n",
       "i64\n",
       "</td>\n",
       "<td>\n",
       "i64\n",
       "</td>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr>\n",
       "<td>\n",
       "0\n",
       "</td>\n",
       "<td>\n",
       "924\n",
       "</td>\n",
       "<td>\n",
       "978300760\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "0\n",
       "</td>\n",
       "<td>\n",
       "2685\n",
       "</td>\n",
       "<td>\n",
       "978300275\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "0\n",
       "</td>\n",
       "<td>\n",
       "1835\n",
       "</td>\n",
       "<td>\n",
       "978824291\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "0\n",
       "</td>\n",
       "<td>\n",
       "1015\n",
       "</td>\n",
       "<td>\n",
       "978302039\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "0\n",
       "</td>\n",
       "<td>\n",
       "2218\n",
       "</td>\n",
       "<td>\n",
       "978300719\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "0\n",
       "</td>\n",
       "<td>\n",
       "515\n",
       "</td>\n",
       "<td>\n",
       "978302268\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "0\n",
       "</td>\n",
       "<td>\n",
       "714\n",
       "</td>\n",
       "<td>\n",
       "978301368\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "0\n",
       "</td>\n",
       "<td>\n",
       "516\n",
       "</td>\n",
       "<td>\n",
       "978824268\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "0\n",
       "</td>\n",
       "<td>\n",
       "733\n",
       "</td>\n",
       "<td>\n",
       "978301752\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "0\n",
       "</td>\n",
       "<td>\n",
       "1876\n",
       "</td>\n",
       "<td>\n",
       "978302281\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "0\n",
       "</td>\n",
       "<td>\n",
       "2308\n",
       "</td>\n",
       "<td>\n",
       "978302124\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "0\n",
       "</td>\n",
       "<td>\n",
       "816\n",
       "</td>\n",
       "<td>\n",
       "978301753\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "...\n",
       "</td>\n",
       "<td>\n",
       "...\n",
       "</td>\n",
       "<td>\n",
       "...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "6033\n",
       "</td>\n",
       "<td>\n",
       "1551\n",
       "</td>\n",
       "<td>\n",
       "956703977\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "6033\n",
       "</td>\n",
       "<td>\n",
       "473\n",
       "</td>\n",
       "<td>\n",
       "956715288\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "6033\n",
       "</td>\n",
       "<td>\n",
       "844\n",
       "</td>\n",
       "<td>\n",
       "964828799\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "6033\n",
       "</td>\n",
       "<td>\n",
       "480\n",
       "</td>\n",
       "<td>\n",
       "956704746\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "6033\n",
       "</td>\n",
       "<td>\n",
       "1554\n",
       "</td>\n",
       "<td>\n",
       "956716207\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "6033\n",
       "</td>\n",
       "<td>\n",
       "1560\n",
       "</td>\n",
       "<td>\n",
       "956704519\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "6033\n",
       "</td>\n",
       "<td>\n",
       "847\n",
       "</td>\n",
       "<td>\n",
       "957717322\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "6033\n",
       "</td>\n",
       "<td>\n",
       "856\n",
       "</td>\n",
       "<td>\n",
       "956704996\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "6033\n",
       "</td>\n",
       "<td>\n",
       "861\n",
       "</td>\n",
       "<td>\n",
       "956704887\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "6033\n",
       "</td>\n",
       "<td>\n",
       "491\n",
       "</td>\n",
       "<td>\n",
       "956704746\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "6033\n",
       "</td>\n",
       "<td>\n",
       "863\n",
       "</td>\n",
       "<td>\n",
       "956715648\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "6033\n",
       "</td>\n",
       "<td>\n",
       "864\n",
       "</td>\n",
       "<td>\n",
       "956715569\n",
       "</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "shape: (574376, 3)\n",
       "┌─────────┬─────────┬───────────┐\n",
       "│ user_id ┆ item_id ┆ event_ts  │\n",
       "│ ---     ┆ ---     ┆ ---       │\n",
       "│ i64     ┆ i64     ┆ i64       │\n",
       "╞═════════╪═════════╪═══════════╡\n",
       "│ 0       ┆ 924     ┆ 978300760 │\n",
       "│ 0       ┆ 2685    ┆ 978300275 │\n",
       "│ 0       ┆ 1835    ┆ 978824291 │\n",
       "│ 0       ┆ 1015    ┆ 978302039 │\n",
       "│ ...     ┆ ...     ┆ ...       │\n",
       "│ 6033    ┆ 861     ┆ 956704887 │\n",
       "│ 6033    ┆ 491     ┆ 956704746 │\n",
       "│ 6033    ┆ 863     ┆ 956715648 │\n",
       "│ 6033    ┆ 864     ┆ 956715569 │\n",
       "└─────────┴─────────┴───────────┘"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.dataset import Dataset\n",
    "from src.postprocess_data import MinInteractionsFilter, IdsEncoder, SplitTrainValTest\n",
    "\n",
    "data = Dataset('ml-1m').get_data()\n",
    "\n",
    "min_iterations_filter = MinInteractionsFilter()\n",
    "ids_encoder = IdsEncoder()\n",
    "\n",
    "data = min_iterations_filter.transform(data)\n",
    "data = ids_encoder.fit_transform(data)\n",
    "\n",
    "n_users = len(data['user_id'].unique())\n",
    "n_items = len(data['item_id'].unique())\n",
    "n_interactions = len(data)\n",
    "print(f'users: {n_users}')\n",
    "print(f'items: {n_items}')\n",
    "print(f'interactions: {n_interactions}')\n",
    "print(f'density: {(n_interactions / n_users / n_items) * 100:.2f}%')\n",
    "\n",
    "splitter = SplitTrainValTest()\n",
    "train_df, val_df, test_df = splitter.transform(data)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b796d4f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4006 users in train\n",
      "1579 users in val\n",
      "1784 users in test\n"
     ]
    }
   ],
   "source": [
    "from src.postprocess_data import create_sparse_dataset, create_positives_dataset\n",
    "\n",
    "train_dataset = create_sparse_dataset(train_df)\n",
    "train_positives = create_positives_dataset(train_df)\n",
    "val_positives = create_positives_dataset(val_df)\n",
    "test_positives = create_positives_dataset(test_df)\n",
    "\n",
    "print(f'{len(train_positives.keys())} users in train')\n",
    "print(f'{len(val_positives.keys())} users in val')\n",
    "print(f'{len(test_positives.keys())} users in test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34461f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c54337ed1a34624858d70662983f936",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import faiss\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from implicit.bpr import BayesianPersonalizedRanking\n",
    "\n",
    "from src.metrics import user_recall, user_ap\n",
    "\n",
    "def linear_lr(epoch, n_epochs, lr_start, lr_end):\n",
    "    p = epoch / n_epochs\n",
    "    return lr_start * (1 - p) + lr_end * p\n",
    "\n",
    "def cosine_annealing_warm_restart(epoch, n_epochs, lr_start, lr_end, t_i):\n",
    "    # https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.html#torch.optim.lr_scheduler.CosineAnnealingWarmRestarts\n",
    "    t_cur = epoch % t_i\n",
    "    # modification to make lr after restart closer to lr_end \n",
    "    linear_coef = (n_epochs - epoch) / n_epochs\n",
    "    return lr_end + linear_coef * (lr_start - lr_end) * (1 + np.cos(np.pi * t_cur / t_i)) / 2\n",
    "\n",
    "class CallbackClass:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def callback_fn(self, epoch, *_):        \n",
    "#         model.learning_rate = cosine_annealing_warm_restart(\n",
    "#             epoch, model.iterations, LR_START, LR_END, RESTART_EPOCHS)\n",
    "#         model.learning_rate = linear_lr(epoch, model.iterations, LR_START, LR_END)\n",
    "        pass\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "DIM = 128\n",
    "LR_START = 1e-2\n",
    "LR_END = 1e-3\n",
    "EPOCHS = 300\n",
    "RESTART_EPOCHS = 100\n",
    "REG_FACTOR = 1e-2\n",
    "\n",
    "def set_seed():\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "def get_model():\n",
    "    return BayesianPersonalizedRanking(\n",
    "        iterations=EPOCHS, factors=(DIM - 1), random_state=SEED,\n",
    "        learning_rate=LR_START, regularization=REG_FACTOR\n",
    "    )\n",
    "\n",
    "set_seed()\n",
    "model = get_model()\n",
    "model.iterations = 0\n",
    "model.fit(train_dataset, callback=CallbackClass().callback_fn)\n",
    "\n",
    "user_factors = model.user_factors.copy()\n",
    "item_factors = model.item_factors.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c34ccf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7270  860 5390 5191 5734 6265  466 4426 5578 8322]\n",
      "-------------------------\n",
      "SEED = 7270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bn/fp1v02yd10zd3f3v4y8t0brc0000gp/T/ipykernel_46256/136960044.py:11: DeprecationWarning: Seeding based on hashing is deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version. The only \n",
      "supported seed types are: None, int, float, str, bytes, and bytearray.\n",
      "  random.seed(SEED)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78b0a3ba85e54da9a888cc53de6aa7d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@5 0.0235\n",
      "MAP@5 0.167\n",
      "Recall@10 0.0411\n",
      "MAP@10 0.1353\n",
      "-------------------------\n",
      "SEED = 860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/Documents/stable_embeddings/src/metrics.py:41: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum([\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6be107a3bed64360b84b5a6594fcabed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@5 0.0233\n",
      "MAP@5 0.1641\n",
      "Recall@10 0.0418\n",
      "MAP@10 0.135\n",
      "-------------------------\n",
      "SEED = 5390\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4ae88f4bebb46db99bbd4b58b01aa62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@5 0.0227\n",
      "MAP@5 0.1673\n",
      "Recall@10 0.04\n",
      "MAP@10 0.1336\n",
      "-------------------------\n",
      "SEED = 5191\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d46382a355c436186997389cd0ef7bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@5 0.0224\n",
      "MAP@5 0.1622\n",
      "Recall@10 0.0406\n",
      "MAP@10 0.1334\n",
      "-------------------------\n",
      "SEED = 5734\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0347e48594d041d78ce1481404ef5720",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@5 0.023\n",
      "MAP@5 0.1682\n",
      "Recall@10 0.0411\n",
      "MAP@10 0.1355\n",
      "-------------------------\n",
      "SEED = 6265\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d5080fadddb4b1391cd0a9e779bb54b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@5 0.0224\n",
      "MAP@5 0.1674\n",
      "Recall@10 0.0408\n",
      "MAP@10 0.1341\n",
      "-------------------------\n",
      "SEED = 466\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa5368625e7244dd9ba249b99b45cc02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@5 0.0233\n",
      "MAP@5 0.1674\n",
      "Recall@10 0.0405\n",
      "MAP@10 0.1339\n",
      "-------------------------\n",
      "SEED = 4426\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68f7c7fba57a4cbb925c67cbf5c7fb98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@5 0.0228\n",
      "MAP@5 0.1676\n",
      "Recall@10 0.0414\n",
      "MAP@10 0.1358\n",
      "-------------------------\n",
      "SEED = 5578\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "797ca7f9c25b4f488f128940bb31ec1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@5 0.0233\n",
      "MAP@5 0.1689\n",
      "Recall@10 0.0415\n",
      "MAP@10 0.1368\n",
      "-------------------------\n",
      "SEED = 8322\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67a15b7cbd084df281103b743413e9b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@5 0.0236\n",
      "MAP@5 0.17\n",
      "Recall@10 0.0427\n",
      "MAP@10 0.1373\n"
     ]
    }
   ],
   "source": [
    "recs_by_seed = []\n",
    "models_by_seed = []\n",
    "\n",
    "seeds = np.random.choice(10_000, 10)\n",
    "print(seeds)\n",
    "\n",
    "for SEED in seeds:\n",
    "    print('-'*25)\n",
    "    print(f'SEED = {SEED}')\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "    \n",
    "    model = get_model()\n",
    "    model.user_factors = user_factors.copy()\n",
    "    model.item_factors = item_factors.copy()\n",
    "    \n",
    "    fit_callback = CallbackClass()\n",
    "    model.fit(train_dataset, callback=fit_callback.callback_fn)\n",
    "\n",
    "    index = faiss.IndexFlatIP(DIM)\n",
    "    index.add(model.item_factors)\n",
    "    recs = index.search(model.user_factors, 50)[1]\n",
    "    \n",
    "    recs_by_seed.append(recs)\n",
    "    models_by_seed.append(model)\n",
    "\n",
    "    for k in [5, 10]:\n",
    "        map_list = []\n",
    "        recall_list = []\n",
    "        for user_id, y_true in test_positives.items():\n",
    "            y_pred = [\n",
    "                item_id for item_id in recs[user_id]\n",
    "                if item_id not in train_positives.get(user_id, set())\n",
    "            ]\n",
    "            map_list.append(user_ap(y_pred, y_true, k))\n",
    "            recall_list.append(user_recall(y_pred, y_true, k))\n",
    "        print(f'Recall@{k}', round(np.mean(recall_list), 4))\n",
    "        print(f'MAP@{k}', round(np.nanmean(map_list), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09766892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9886669995007489\n",
      "0.9879181228157764\n",
      "0.9872566150773838\n",
      "0.987156764852721\n",
      "0.987855716425362\n",
      "0.9870943584623065\n",
      "0.987443834248627\n",
      "0.9879056415376934\n",
      "0.9889540688966549\n"
     ]
    }
   ],
   "source": [
    "k = 20\n",
    "for i in range(1, len(recs_by_seed)):\n",
    "    intersection_count = []\n",
    "    for prev_recs, cur_recs in zip(\n",
    "        recs_by_seed[0][list(train_positives.keys())],\n",
    "        recs_by_seed[i][list(train_positives.keys())]\n",
    "    ):\n",
    "        intersection_count.append(len(set(cur_recs[:k]).intersection(prev_recs)))\n",
    "    print(np.mean(intersection_count) / k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29d28c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_tau = [model.user_factors - user_factors for model in models_by_seed]\n",
    "item_tau = [model.item_factors - item_factors for model in models_by_seed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c18089e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "5 0.03458366021707631\n",
      "10 0.058864378615636356\n",
      "-------------------------\n",
      "0.014949494949494949\n",
      "5 0.035196662138405374\n",
      "10 0.05868251139058492\n",
      "-------------------------\n",
      "0.0198989898989899\n",
      "5 0.035351591386880175\n",
      "10 0.05847477881814231\n",
      "-------------------------\n",
      "0.02484848484848485\n",
      "5 0.035094779107870414\n",
      "10 0.058847781882582585\n",
      "-------------------------\n",
      "0.029797979797979796\n",
      "5 0.03420458024653849\n",
      "10 0.057633498450128655\n",
      "-------------------------\n",
      "0.03474747474747475\n",
      "5 0.03425606114077181\n",
      "10 0.05712097185551786\n",
      "-------------------------\n",
      "0.039696969696969696\n",
      "5 0.03412511791527526\n",
      "10 0.05697601388713112\n",
      "-------------------------\n",
      "0.04464646464646465\n",
      "5 0.03389789908978116\n",
      "10 0.05644853817587903\n",
      "-------------------------\n",
      "0.049595959595959596\n",
      "5 0.03366165027668469\n",
      "10 0.05607936216133426\n",
      "-------------------------\n",
      "0.05454545454545454\n",
      "5 0.033434380959208025\n",
      "10 0.0560672194726428\n",
      "-------------------------\n",
      "0.059494949494949496\n",
      "5 0.03328880786452526\n",
      "10 0.055904872098816775\n",
      "-------------------------\n",
      "0.06444444444444444\n",
      "5 0.03321526809902793\n",
      "10 0.055741680653326464\n",
      "-------------------------\n",
      "0.06939393939393938\n",
      "5 0.033210974797629474\n",
      "10 0.055717747997293524\n",
      "-------------------------\n",
      "0.07434343434343434\n",
      "5 0.033437020481789224\n",
      "10 0.05590698115488548\n",
      "-------------------------\n",
      "0.07929292929292929\n",
      "5 0.03331746955476521\n",
      "10 0.0558150633237204\n",
      "-------------------------\n",
      "0.08424242424242423\n",
      "5 0.03316870582433299\n",
      "10 0.055776902252972535\n",
      "-------------------------\n",
      "0.08919191919191918\n",
      "5 0.03246025874240541\n",
      "10 0.05540943789776647\n",
      "-------------------------\n",
      "0.09414141414141414\n",
      "5 0.032349980494632245\n",
      "10 0.05531028295377302\n",
      "-------------------------\n",
      "0.09909090909090908\n",
      "5 0.03230911177527412\n",
      "10 0.055252895871706974\n",
      "-------------------------\n",
      "0.10404040404040403\n",
      "5 0.03226377852854758\n",
      "10 0.05524721230047559\n",
      "-------------------------\n",
      "0.10898989898989898\n",
      "5 0.032255220255264797\n",
      "10 0.054546174391924246\n",
      "-------------------------\n",
      "0.11393939393939392\n",
      "5 0.03227258231389215\n",
      "10 0.05455262578978087\n",
      "-------------------------\n",
      "0.11888888888888888\n",
      "5 0.032268757964719896\n",
      "10 0.05442123713457684\n",
      "-------------------------\n",
      "0.12383838383838383\n",
      "5 0.03230616347993003\n",
      "10 0.054463457949438576\n",
      "-------------------------\n",
      "0.12878787878787878\n",
      "5 0.032319180459676154\n",
      "10 0.054417476603210425\n",
      "-------------------------\n",
      "0.13373737373737374\n",
      "5 0.032302610536182906\n",
      "10 0.054417476603210425\n",
      "-------------------------\n",
      "0.1386868686868687\n",
      "5 0.03229193348307394\n",
      "10 0.05439447167203577\n",
      "-------------------------\n",
      "0.14363636363636365\n",
      "5 0.03226649273565726\n",
      "10 0.0543301193967088\n",
      "-------------------------\n",
      "0.1485858585858586\n",
      "5 0.032266154272872064\n",
      "10 0.054313155676451855\n",
      "-------------------------\n",
      "0.15353535353535352\n",
      "5 0.032216310255326966\n",
      "10 0.05429255879558991\n",
      "-------------------------\n",
      "0.15848484848484848\n",
      "5 0.03220824811382869\n",
      "10 0.05429255879558991\n",
      "-------------------------\n",
      "0.16343434343434343\n",
      "5 0.03220305703003422\n",
      "10 0.05429255879558991\n",
      "-------------------------\n",
      "0.16838383838383839\n",
      "5 0.03220305703003422\n",
      "10 0.054280379714379795\n",
      "-------------------------\n",
      "0.17333333333333334\n",
      "5 0.03219013229079083\n",
      "10 0.054280379714379795\n",
      "-------------------------\n",
      "0.1782828282828283\n",
      "5 0.032177953209580716\n",
      "10 0.054280379714379795\n",
      "-------------------------\n",
      "0.18323232323232325\n",
      "5 0.032177953209580716\n",
      "10 0.05427467419885794\n",
      "-------------------------\n",
      "0.18818181818181817\n",
      "5 0.03216857639484373\n",
      "10 0.05426315943116838\n",
      "-------------------------\n",
      "0.19313131313131313\n",
      "5 0.032158361681570734\n",
      "10 0.05426315943116838\n",
      "-------------------------\n",
      "0.19808080808080808\n",
      "5 0.032158361681570734\n",
      "10 0.054217241313310294\n",
      "-------------------------\n",
      "0.20303030303030303\n",
      "5 0.0321465975356732\n",
      "10 0.05422030871483862\n",
      "-------------------------\n",
      "0.207979797979798\n",
      "5 0.0321465975356732\n",
      "10 0.05577043482845152\n",
      "-------------------------\n",
      "0.21292929292929294\n",
      "5 0.03212126504675617\n",
      "10 0.05566362621942632\n",
      "-------------------------\n",
      "0.21787878787878787\n",
      "5 0.03212126504675617\n",
      "10 0.05564603421323393\n",
      "-------------------------\n",
      "0.22282828282828282\n",
      "5 0.03212126504675617\n",
      "10 0.05564603421323393\n",
      "-------------------------\n",
      "0.22777777777777777\n",
      "5 0.03212126504675617\n",
      "10 0.05564603421323393\n",
      "-------------------------\n",
      "0.23272727272727273\n",
      "5 0.03212126504675617\n",
      "10 0.05564603421323393\n",
      "-------------------------\n",
      "0.23767676767676768\n",
      "5 0.032088958231645856\n",
      "10 0.05563385513202382\n",
      "-------------------------\n",
      "0.24262626262626263\n",
      "5 0.032088958231645856\n",
      "10 0.05561054822519147\n",
      "-------------------------\n",
      "0.24757575757575756\n",
      "5 0.032088958231645856\n",
      "10 0.05559678056817135\n",
      "-------------------------\n",
      "0.2525252525252525\n",
      "5 0.032088958231645856\n",
      "10 0.05559678056817135\n",
      "-------------------------\n",
      "0.25747474747474747\n",
      "5 0.032088958231645856\n",
      "10 0.05559678056817135\n",
      "-------------------------\n",
      "0.26242424242424245\n",
      "5 0.032088958231645856\n",
      "10 0.05559678056817135\n",
      "-------------------------\n",
      "0.2673737373737374\n",
      "5 0.032083252716124\n",
      "10 0.05559678056817135\n",
      "-------------------------\n",
      "0.2723232323232323\n",
      "5 0.032083252716124\n",
      "10 0.05559678056817135\n",
      "-------------------------\n",
      "0.2772727272727273\n",
      "5 0.032083252716124\n",
      "10 0.05559678056817135\n",
      "-------------------------\n",
      "0.2822222222222222\n",
      "5 0.032073038002850995\n",
      "10 0.05559678056817135\n",
      "-------------------------\n",
      "0.2871717171717172\n",
      "5 0.03210637022511025\n",
      "10 0.05563502218750755\n",
      "-------------------------\n",
      "0.2921212121212121\n",
      "5 0.03209917349530428\n",
      "10 0.05563502218750755\n",
      "-------------------------\n",
      "0.29707070707070704\n",
      "5 0.03206584127304502\n",
      "10 0.055601689965248294\n",
      "-------------------------\n",
      "0.302020202020202\n",
      "5 0.03205393690795243\n",
      "10 0.05563502218750755\n",
      "-------------------------\n",
      "0.30696969696969695\n",
      "5 0.03205393690795243\n",
      "10 0.05564067676092654\n",
      "-------------------------\n",
      "0.31191919191919193\n",
      "5 0.03205393690795243\n",
      "10 0.0556269091039064\n",
      "-------------------------\n",
      "0.31686868686868686\n",
      "5 0.03205393690795243\n",
      "10 0.0556269091039064\n",
      "-------------------------\n",
      "0.32181818181818184\n",
      "5 0.03205393690795243\n",
      "10 0.0556269091039064\n",
      "-------------------------\n",
      "0.32676767676767676\n",
      "5 0.03205393690795243\n",
      "10 0.05560157661498937\n",
      "-------------------------\n",
      "0.3317171717171717\n",
      "5 0.03205393690795243\n",
      "10 0.05560157661498937\n",
      "-------------------------\n",
      "0.33666666666666667\n",
      "5 0.03204977038017002\n",
      "10 0.05560157661498937\n",
      "-------------------------\n",
      "0.3416161616161616\n",
      "5 0.03204977038017002\n",
      "10 0.05560157661498937\n",
      "-------------------------\n",
      "0.3465656565656566\n",
      "5 0.03206128514785958\n",
      "10 0.05560669428951806\n",
      "-------------------------\n",
      "0.3515151515151515\n",
      "5 0.03206128514785958\n",
      "10 0.055602527761735666\n",
      "-------------------------\n",
      "0.3564646464646465\n",
      "5 0.03206128514785958\n",
      "10 0.055589963979193024\n",
      "-------------------------\n",
      "0.3614141414141414\n",
      "5 0.03206128514785958\n",
      "10 0.055589963979193024\n",
      "-------------------------\n",
      "0.36636363636363634\n",
      "5 0.03206128514785958\n",
      "10 0.055589963979193024\n",
      "-------------------------\n",
      "0.3713131313131313\n",
      "5 0.03206128514785958\n",
      "10 0.055589963979193024\n",
      "-------------------------\n",
      "0.37626262626262624\n",
      "5 0.03206128514785958\n",
      "10 0.055589963979193024\n",
      "-------------------------\n",
      "0.3812121212121212\n",
      "5 0.03206128514785958\n",
      "10 0.055589963979193024\n",
      "-------------------------\n",
      "0.38616161616161615\n",
      "5 0.03206128514785958\n",
      "10 0.05558556597764492\n",
      "-------------------------\n",
      "0.3911111111111111\n",
      "5 0.03206128514785958\n",
      "10 0.05557964717182319\n",
      "-------------------------\n",
      "0.39606060606060606\n",
      "5 0.03204461903672995\n",
      "10 0.05557964717182319\n",
      "-------------------------\n",
      "0.401010101010101\n",
      "5 0.03204461903672995\n",
      "10 0.05557964717182319\n",
      "-------------------------\n",
      "0.40595959595959596\n",
      "5 0.03204461903672995\n",
      "10 0.05557964717182319\n",
      "-------------------------\n",
      "0.4109090909090909\n",
      "5 0.03204461903672995\n",
      "10 0.05557964717182319\n",
      "-------------------------\n",
      "0.41585858585858587\n",
      "5 0.03204461903672995\n",
      "10 0.05557964717182319\n",
      "-------------------------\n",
      "0.4208080808080808\n",
      "5 0.032002398221868227\n",
      "10 0.05564297839411578\n",
      "-------------------------\n",
      "0.4257575757575757\n",
      "5 0.032002398221868227\n",
      "10 0.05564297839411578\n",
      "-------------------------\n",
      "0.4307070707070707\n",
      "5 0.032002398221868227\n",
      "10 0.055635781664309804\n",
      "-------------------------\n",
      "0.43565656565656563\n",
      "5 0.032002398221868227\n",
      "10 0.055635781664309804\n",
      "-------------------------\n",
      "0.4406060606060606\n",
      "5 0.032002398221868227\n",
      "10 0.055635781664309804\n",
      "-------------------------\n",
      "0.44555555555555554\n",
      "5 0.032002398221868227\n",
      "10 0.055635781664309804\n",
      "-------------------------\n",
      "0.4505050505050505\n",
      "5 0.032002398221868227\n",
      "10 0.055635781664309804\n",
      "-------------------------\n",
      "0.45545454545454545\n",
      "5 0.032002398221868227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.055635781664309804\n",
      "-------------------------\n",
      "0.46040404040404037\n",
      "5 0.032002398221868227\n",
      "10 0.055614456210283714\n",
      "-------------------------\n",
      "0.46535353535353535\n",
      "5 0.032002398221868227\n",
      "10 0.055614456210283714\n",
      "-------------------------\n",
      "0.4703030303030303\n",
      "5 0.032002398221868227\n",
      "10 0.055614456210283714\n",
      "-------------------------\n",
      "0.47525252525252526\n",
      "5 0.032002398221868227\n",
      "10 0.055614456210283714\n",
      "-------------------------\n",
      "0.4802020202020202\n",
      "5 0.032002398221868227\n",
      "10 0.055614456210283714\n",
      "-------------------------\n",
      "0.4851515151515151\n",
      "5 0.032002398221868227\n",
      "10 0.055604241497010716\n",
      "-------------------------\n",
      "0.4901010101010101\n",
      "5 0.032002398221868227\n",
      "10 0.055577853487722144\n",
      "-------------------------\n",
      "0.495050505050505\n",
      "5 0.032002398221868227\n",
      "10 0.055577853487722144\n",
      "-------------------------\n",
      "0.5\n",
      "5 0.032002398221868227\n",
      "10 0.055577853487722144\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "best_init_alpha, best_score = None, None\n",
    "for init_alpha in np.linspace(0.01, 0.5, 100):\n",
    "    new_item_factors = item_factors.copy()\n",
    "    new_user_factors = user_factors.copy()\n",
    "\n",
    "    alpha = init_alpha\n",
    "    for tau in item_tau:\n",
    "        new_item_factors += alpha * tau\n",
    "\n",
    "    alpha = init_alpha\n",
    "    for tau in user_tau:\n",
    "        new_user_factors += alpha * tau\n",
    "\n",
    "    index = faiss.IndexFlatIP(DIM)\n",
    "    index.add(new_item_factors)\n",
    "    recs = index.search(new_user_factors, 30)[1]\n",
    "\n",
    "    print(init_alpha)\n",
    "    for k in [5, 10]:\n",
    "        recall_list = []\n",
    "        for user_id, y_true in val_positives.items():\n",
    "            y_pred = [\n",
    "                item_id for item_id in recs[user_id]\n",
    "                if item_id not in train_positives.get(user_id, set())\n",
    "            ]\n",
    "            recall_list.append(user_recall(y_pred, y_true, k))\n",
    "        print(k, np.mean(recall_list))\n",
    "        \n",
    "        if k == 10:\n",
    "            if best_score is None or best_score < np.mean(recall_list):\n",
    "                best_init_alpha, best_score = init_alpha, np.mean(recall_list)\n",
    "    print('-'*25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e5b3a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init_alpha = 0.01\n",
      "Recall@5 0.0281\n",
      "MAP@5 0.1958\n",
      "Recall@10 0.0502\n",
      "MAP@10 0.1563\n"
     ]
    }
   ],
   "source": [
    "from src.metrics import user_recall, user_ap\n",
    "\n",
    "\n",
    "init_alpha = best_init_alpha\n",
    "print(f'init_alpha = {init_alpha}')\n",
    "\n",
    "new_item_factors = item_factors.copy()\n",
    "new_user_factors = user_factors.copy()\n",
    "\n",
    "alpha = init_alpha\n",
    "for tau in item_tau:\n",
    "    new_item_factors += alpha * tau\n",
    "    \n",
    "alpha = init_alpha\n",
    "for tau in user_tau:\n",
    "    new_user_factors += alpha * tau\n",
    "\n",
    "index = faiss.IndexFlatIP(DIM)\n",
    "index.add(new_item_factors)\n",
    "recs = index.search(new_user_factors, 50)[1]\n",
    "\n",
    "for k in [5, 10]:\n",
    "    map_list = []\n",
    "    recall_list = []\n",
    "    for user_id, y_true in test_positives.items():\n",
    "        y_pred = [\n",
    "            item_id for item_id in recs[user_id]\n",
    "            if item_id not in train_positives.get(user_id, set())\n",
    "        ]\n",
    "        map_list.append(user_ap(y_pred, y_true, k))\n",
    "        recall_list.append(user_recall(y_pred, y_true, k))\n",
    "    print(f'Recall@{k}', round(np.mean(recall_list), 4))\n",
    "    print(f'MAP@{k}', round(np.nanmean(map_list), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69515508",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@5 0.0235\n",
      "MAP@5 0.167\n",
      "Recall@10 0.0411\n",
      "MAP@10 0.1353\n",
      "-------------------------\n",
      "Recall@5 0.0233\n",
      "MAP@5 0.1641\n",
      "Recall@10 0.0418\n",
      "MAP@10 0.135\n",
      "-------------------------\n",
      "Recall@5 0.0227\n",
      "MAP@5 0.1673\n",
      "Recall@10 0.04\n",
      "MAP@10 0.1336\n",
      "-------------------------\n",
      "Recall@5 0.0224\n",
      "MAP@5 0.1622\n",
      "Recall@10 0.0406\n",
      "MAP@10 0.1334\n",
      "-------------------------\n",
      "Recall@5 0.023\n",
      "MAP@5 0.1682\n",
      "Recall@10 0.0411\n",
      "MAP@10 0.1355\n",
      "-------------------------\n",
      "Recall@5 0.0224\n",
      "MAP@5 0.1674\n",
      "Recall@10 0.0408\n",
      "MAP@10 0.1341\n",
      "-------------------------\n",
      "Recall@5 0.0233\n",
      "MAP@5 0.1674\n",
      "Recall@10 0.0405\n",
      "MAP@10 0.1339\n",
      "-------------------------\n",
      "Recall@5 0.0228\n",
      "MAP@5 0.1676\n",
      "Recall@10 0.0414\n",
      "MAP@10 0.1358\n",
      "-------------------------\n",
      "Recall@5 0.0233\n",
      "MAP@5 0.1689\n",
      "Recall@10 0.0415\n",
      "MAP@10 0.1368\n",
      "-------------------------\n",
      "Recall@5 0.0236\n",
      "MAP@5 0.17\n",
      "Recall@10 0.0427\n",
      "MAP@10 0.1373\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "for model in models_by_seed:\n",
    "    index = faiss.IndexFlatIP(DIM)\n",
    "    index.add(model.item_factors)\n",
    "    recs = index.search(model.user_factors, 50)[1]\n",
    "\n",
    "    for k in [5, 10]:\n",
    "        map_list = []\n",
    "        recall_list = []\n",
    "        for user_id, y_true in test_positives.items():\n",
    "            y_pred = [\n",
    "                item_id for item_id in recs[user_id]\n",
    "                if item_id not in train_positives.get(user_id, set())\n",
    "            ]\n",
    "            map_list.append(user_ap(y_pred, y_true, k))\n",
    "            recall_list.append(user_recall(y_pred, y_true, k))\n",
    "        print(f'Recall@{k}', round(np.mean(recall_list), 4))\n",
    "        print(f'MAP@{k}', round(np.nanmean(map_list), 4))\n",
    "    print('-'*25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8bc58c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@5 0.0231\n",
      "MAP@5 0.169\n",
      "Recall@10 0.0425\n",
      "MAP@10 0.1362\n"
     ]
    }
   ],
   "source": [
    "new_user_factors = np.mean([model.user_factors for model in models_by_seed], axis=0)\n",
    "new_item_factors = np.mean([model.item_factors for model in models_by_seed], axis=0)\n",
    "\n",
    "index = faiss.IndexFlatIP(DIM)\n",
    "index.add(new_item_factors)\n",
    "recs = index.search(new_user_factors, 50)[1]\n",
    "\n",
    "for k in [5, 10]:\n",
    "    map_list = []\n",
    "    recall_list = []\n",
    "    for user_id, y_true in test_positives.items():\n",
    "        y_pred = [\n",
    "            item_id for item_id in recs[user_id]\n",
    "            if item_id not in train_positives.get(user_id, set())\n",
    "        ]\n",
    "        map_list.append(user_ap(y_pred, y_true, k))\n",
    "        recall_list.append(user_recall(y_pred, y_true, k))\n",
    "    print(f'Recall@{k}', round(np.mean(recall_list), 4))\n",
    "    print(f'MAP@{k}', round(np.nanmean(map_list), 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
